{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script walks the user through calibration of the FiLM-Scope, using an example calibration dataset (see README for download information). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from filmscope.calibration import (SystemVertexParser, CalibrationInfoManager, SystemCalibrator,\n",
    "                                   Filmscope_System)\n",
    "from filmscope.util import load_graph_images, load_dictionary, generate_A_matrix\n",
    "from filmscope.config import path_to_data\n",
    "from matplotlib import pyplot as plt \n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Parse Vertices\n",
    "\n",
    "This will load the calibration dataset with images of the graph target, and extract the location of the graph vertices in all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set image_folder to the path of the folder with the graph calibration images\n",
    "# and calibration_filename to the filename where the calibration information will be stored\n",
    "\n",
    "image_folder = path_to_data + \"/calibration_data\"\n",
    "calibration_filename = image_folder + \"/calibration_information\"\n",
    "\n",
    "info_manager = CalibrationInfoManager(calibration_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#known information\n",
    "# spacing between vertices in the calibration graph\n",
    "info_manager.vertex_spacing_m = 0.004357142857142857\n",
    "# pixel size for the FiLMScope\n",
    "info_manager.pixel_size = 1.1e-6\n",
    "\n",
    "info_manager.save_all_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify file naming convention for the graph images \n",
    "# name_dict just needs to contain a unique portion of the string \n",
    "# for the graph images to be used here\n",
    "num_graphs = 7\n",
    "name_dict = {}\n",
    "for i in range(num_graphs):\n",
    "    name_dict[i] = f\"graph_0{i}\"\n",
    "\n",
    "info_manager.plane_names = name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size sets how many images will be loaded at once \n",
    "batch_size = 16 \n",
    "all_planes = np.arange(num_graphs)\n",
    "# 48 images are used in this dataset\n",
    "all_cam_nums = np.arange(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display an image to manually set the expected spacing between graph vertices\n",
    "# this graph target has both \"major\" and \"minor\" lines, and we only extract vertices\n",
    "# of the major lines\n",
    "img = load_graph_images(\n",
    "    folder=image_folder, image_numbers=[all_cam_nums[0]], plane_numbers=[all_planes[0]],\n",
    "    calibration_filename=calibration_filename\n",
    ")[all_planes[0]][all_cam_nums[0]]\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_spacing = int(2410 - 1920)\n",
    "print(expected_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to select the plane and camera numbers\n",
    "# for the next set of images to be processed\n",
    "# IMPORTANT NOTE: right now the vertex parser has to have\n",
    "# the same number of cameras in all planes,\n",
    "# so when batching is used, we only use images from one plane at a time\n",
    "def get_camera_plane_numbers(batch_size, all_planes, all_cameras):\n",
    "    info_manager = CalibrationInfoManager(calibration_filename)\n",
    "    vertices = info_manager.all_vertices\n",
    "\n",
    "    plane_numbers = []\n",
    "    camera_numbers = []\n",
    "    num_images = 0\n",
    "    chosen_plane = False\n",
    "    for plane in all_planes:\n",
    "        if plane not in vertices:\n",
    "            chosen_plane = True\n",
    "            camera_numbers = all_cameras[:batch_size]\n",
    "            plane_numbers.append(plane)\n",
    "            break\n",
    "        else:\n",
    "            cam_vertices = vertices[plane]\n",
    "            for cam in all_cameras:\n",
    "                if cam in cam_vertices:\n",
    "                    continue\n",
    "                else:\n",
    "                    chosen_plane = True\n",
    "                camera_numbers.append(cam)\n",
    "                num_images = num_images + 1\n",
    "                if num_images >= batch_size:\n",
    "                    break\n",
    "            if chosen_plane:\n",
    "                plane_numbers.append(plane)\n",
    "                break\n",
    "    if not chosen_plane:\n",
    "        return [-1], [-1]\n",
    "    return np.asarray(plane_numbers), np.asarray(camera_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through one set of images to ensure parsing settings are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_numbers, camera_numbers = get_camera_plane_numbers(\n",
    "    batch_size, all_planes, all_cam_nums\n",
    ")\n",
    "if plane_numbers[0] == -1:\n",
    "    print(\"Done! All vertices found!\")\n",
    "else:\n",
    "    print(\"plane:\", plane_numbers, \"camera numbers:\", camera_numbers)\n",
    "\n",
    "\n",
    "all_images = load_graph_images(\n",
    "    folder=image_folder,\n",
    "    image_numbers=camera_numbers,\n",
    "    plane_numbers=plane_numbers,\n",
    "    calibration_filename=calibration_filename\n",
    ")\n",
    "\n",
    "parser = SystemVertexParser(\n",
    "    calibration_filename,\n",
    "    expected_vertex_spacing=expected_spacing,\n",
    "    all_images=all_images,\n",
    "    camera_numbers=camera_numbers,\n",
    "    plane_numbers=plane_numbers,\n",
    "    display_downsample=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to adjust threshold values\n",
    "# see the README in the calibration folder\n",
    "# for more info on settings these values  \n",
    "threshold_values = {\n",
    "    # used in \"cv2.adaptiveThreshold\" to convert graph images to binary images\n",
    "    # should be an add number that approximately matches the expected spacing\n",
    "    \"adaptive_threshold_range\": 2 * int(expected_spacing / 2) + 1,\n",
    "    # used in cv2.medianBlur to filter the binary image\n",
    "    # larger numbers will blur out smaller features in the image other than the\n",
    "    # graph lines we are trying to identify\n",
    "    \"blur_range\": 47,\n",
    "    # \"edge_thresh\" and \"edge_aperture\" are used in cv2.Canny\n",
    "    # to identify edges in the images. \n",
    "    # consult cv2 documentation for use\n",
    "    \"edge_thresh1\": 50,\n",
    "    \"edge_thresh2\": 200,\n",
    "    \"edge_aperture\": 5,\n",
    "    # line_thresh_per_pixel * #pixel used in cv2.HoughLines to \n",
    "    # identify lines from edges\n",
    "    \"line_thresh_per_pixel\": 0.08,\n",
    "}\n",
    "\n",
    "# uncomment this line to use the default threshold values\n",
    "# threshold_values = None\n",
    "\n",
    "# select a camera # and plane # from the list of loaded images\n",
    "# to manually adjust threshold values for that image \n",
    "cam = camera_numbers[0]\n",
    "plane = plane_numbers[0]\n",
    "parser.find_lines(\n",
    "    cam, plane, show=True, show_process=True, threshold_values=threshold_values\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the settings seem reasonable, find the remaining lines\n",
    "parser.find_all_remaining_lines(show=False, threshold_values=threshold_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click this cell multiple times until all vertices have been found\n",
    "# it will show the results for \"display_size\" results at a time\n",
    "# to confirm the results are adequate\n",
    "\n",
    "# if not (a large number of vertices are not identified or many extraneous vertices are)\n",
    "# go back two cells to fix the threshold values\n",
    "display_size = 4\n",
    "parser.find_all_remaining_vertices(show=True, max_display=display_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.remove_nan_points()\n",
    "parser.save_all_parameters()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once settings are adequate, this cell will do the remaining processing\n",
    "# to find the vertices for all images\n",
    "while True:\n",
    "    plane_numbers, camera_numbers = get_camera_plane_numbers(\n",
    "        batch_size, all_planes, all_cam_nums\n",
    "    )\n",
    "    if plane_numbers[0] == -1:\n",
    "        print(\"Done! All vertices found!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"planes:\",plane_numbers, \"image #:\", camera_numbers)\n",
    "\n",
    "    all_images = load_graph_images(\n",
    "        folder=image_folder,\n",
    "        image_numbers=camera_numbers,\n",
    "        plane_numbers=plane_numbers,\n",
    "        calibration_filename=calibration_filename\n",
    "    )\n",
    "\n",
    "    parser = SystemVertexParser(\n",
    "        calibration_filename=calibration_filename,\n",
    "        expected_vertex_spacing=expected_spacing,\n",
    "        all_images=all_images,\n",
    "        camera_numbers=camera_numbers,\n",
    "        plane_numbers=plane_numbers,\n",
    "        display_downsample=4,\n",
    "    )\n",
    "\n",
    "    parser.find_all_remaining_lines(show=False, max_display=100)\n",
    "    parser.find_all_remaining_vertices(show=False, max_display=100)\n",
    "    parser.remove_nan_points()\n",
    "    parser.save_all_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Remove extraneous vertices\n",
    "\n",
    "While this step can be improved in future versions, right now extraneous vertices must be manually removed, or they will impact the calibration results. This can be done by running ``remove_vertices.py`` (first open the file and adjust necessary settings). For demo purposes, this step can be skipped by running the cell below to use previously identified vertices for later steps in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to proceed with previously identified vertices\n",
    "demo_calibration_filename = image_folder + '/calibration_information_example'\n",
    "info_manager = CalibrationInfoManager(calibration_filename)\n",
    "info_manager.all_vertices = load_dictionary(demo_calibration_filename)[\"all_vertices\"]\n",
    "info_manager.save_all_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: identify approximate alignment points between images\n",
    "\n",
    "This step can likely be automated in future versions of the code, but right now the user must manually select approximate alignment points between the images. This can be done by finding a feature visible in all 48 images, then running ``select_alignment_points.py`` to click on that point in all the images. This step can be skipped in the demo by running the cell below to use previously identified alignment points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to proceed with previously identified alignment points\n",
    "demo_calibration_filename = image_folder + '/calibration_information_example'\n",
    "info_manager = CalibrationInfoManager(calibration_filename)\n",
    "info_manager.approx_alignment_points = load_dictionary(demo_calibration_filename)[\"approx_alignment_points\"]\n",
    "info_manager.save_all_info()\n",
    "\n",
    "# confirm that was done correctly \n",
    "assert len(info_manager.approx_alignment_points) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Fit calibration coefficients \n",
    "\n",
    "In this portion, the identified graph vertices are used to perform inter- and intr-camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be uncommented to display interactive plots\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be set to any camera, but we recommend using one of the 4 center cameras\n",
    "# (20, 21, 26 or 27)\n",
    "reference_camera = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select reference plane based on how many vertices were identified in each plane\n",
    "# the first number gives the total number of vertices identified in a given plane \n",
    "# between all 48 images\n",
    "# and the second number is the number of identified vertices in the image with the \n",
    "# least identified vertices.\n",
    "# both of these numbers should be reasonably large in the chosen reference plane\n",
    "vertices = load_dictionary(calibration_filename)['all_vertices']\n",
    "\n",
    "for plane_num, values in vertices.items():\n",
    "    plane_points = 0\n",
    "    min_points = np.inf\n",
    "    for cam, points in values.items():\n",
    "        plane_points = plane_points + len(points) \n",
    "        min_points = min(min_points, len(points))\n",
    "    print(plane_num, \"total points:\", plane_points, \", mininum points in an image:\", min_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_plane = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_separation_mm = 1 \n",
    "calibrator = SystemCalibrator(\n",
    "    calibration_filename=calibration_filename,\n",
    "    reference_plane=reference_plane,\n",
    "    reference_camera=reference_camera,\n",
    "    plane_separation_mm = plane_separation_mm,\n",
    "    ref_plane_image_folder = None,\n",
    "    useable_plane_numbers = None # if None, this will use all planes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator.run_inter_camera_calibration(show=True, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator.run_slope_calibration(show=True, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: check if results look reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = Filmscope_System(calibration_filename)\n",
    "plane_separation_mm = system.calib_manager.plane_separation_mm\n",
    "calibrator = SystemCalibrator(calibration_filename)\n",
    "calibrator.get_all_camera_vertices_matrices()\n",
    "all_camera_vertices_matrices = calibrator.all_camera_vertices_matrices\n",
    "\n",
    "image_shape = system.calib_manager.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_comparison_plot(camera_number, vector_length_mm=None):\n",
    "    slope0, slope1 = calibrator.get_slopes_from_vertices_matrices(camera_number)\n",
    "    vertices_matrices = all_camera_vertices_matrices[camera_number]\n",
    "\n",
    "    plt.figure()\n",
    "    matrix_shape = vertices_matrices.shape[1:3]\n",
    "    first = True\n",
    "    for i, j in np.ndindex(matrix_shape):\n",
    "        if first:\n",
    "            label1 = \"Comptuted slope vector\"\n",
    "            label2 = \"Fit slope\"\n",
    "            label3 = \"Vertex locations\"\n",
    "        else:\n",
    "            label1 = None\n",
    "            label2 = None\n",
    "            label3 = None\n",
    "\n",
    "        X = vertices_matrices[:, i, j, 0]\n",
    "        Y = vertices_matrices[:, i, j, 1]\n",
    "\n",
    "        if not np.isnan(slope0[i, j]):\n",
    "            if vector_length_mm is None:\n",
    "                start_plane_mm = (\n",
    "                    np.where(~np.isnan(X))[0][0] - system.reference_plane\n",
    "                ) * plane_separation_mm\n",
    "                end_plane_mm = (\n",
    "                    np.where(~np.isnan(X))[0][-1] - system.reference_plane\n",
    "                ) * plane_separation_mm\n",
    "            else:\n",
    "                start_plane_mm = -vector_length_mm / 2\n",
    "                end_plane_mm = vector_length_mm / 2\n",
    "\n",
    "            x = vertices_matrices[system.reference_plane, i, j, 0]\n",
    "            y = vertices_matrices[system.reference_plane, i, j, 1]\n",
    "\n",
    "            # plot the slope vector that was fit to that point\n",
    "            coeff0, coeff1 = system._get_slope_coeffs(camera_number)\n",
    "            slope_matrix = generate_A_matrix(system.shift_order, [x], [y])\n",
    "            v1 = np.matmul(slope_matrix, coeff0)[0]\n",
    "            v0 = np.matmul(slope_matrix, coeff1)[0]\n",
    "            x_start = x + v0 * start_plane_mm\n",
    "            x_end = x + v0 * end_plane_mm\n",
    "            y_start = y + v1 * start_plane_mm\n",
    "            y_end = y + v1 * end_plane_mm\n",
    "            plt.plot(\n",
    "                [x_start, x, x_end],\n",
    "                [y_start, y, y_end],\n",
    "                \"-\",\n",
    "                linewidth=3,\n",
    "                color=\"blue\",\n",
    "                label=label2,\n",
    "            )\n",
    "\n",
    "            s0 = slope0[i, j]\n",
    "            s1 = slope1[i, j]\n",
    "            x_start = x + s0 * start_plane_mm / plane_separation_mm\n",
    "            x_end = x + s0 * end_plane_mm / plane_separation_mm\n",
    "            y_start = y + s1 * start_plane_mm / plane_separation_mm\n",
    "            y_end = y + s1 * end_plane_mm / plane_separation_mm\n",
    "\n",
    "            # plot the originally calculated slope vector\n",
    "            plt.plot(\n",
    "                [x_start, x, x_end],\n",
    "                [y_start, y, y_end],\n",
    "                \"-\",\n",
    "                markersize=2,\n",
    "                color=\"orange\",\n",
    "                label=label1,\n",
    "            )\n",
    "\n",
    "        if False in np.isnan(X):\n",
    "            plt.plot(X, Y, \".\", markersize=3, color=\"red\", label=label3)\n",
    "            first = False\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    if vector_length_mm is not None:\n",
    "        title = f\"Slopes for camera {camera_number}, \\n shown for {vector_length_mm} mm axial shift\"\n",
    "    else:\n",
    "        title = f\"Slopes for camera {camera_number}, \\n vector length varies to match location of located vertices\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.xlim([0, image_shape[0]])\n",
    "    plt.ylim([0, image_shape[1]])\n",
    "\n",
    "\n",
    "make_comparison_plot(13, vector_length_mm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next plot: choose points in the image and plot lines that show how those points shift ?\n",
    "# https://stackoverflow.com/questions/14777066/matplotlib-discrete-colorbar\n",
    "def vector_plot(\n",
    "    camera_number, vector_length_mm=10, ax=None, add_colorbar=True, add_title=True, s=50\n",
    "):\n",
    "    coeffs0, coeffs1 = system._get_slope_coeffs(camera_number)\n",
    "\n",
    "    # pick locations in the image\n",
    "    x_locs = np.linspace(0, image_shape[0], 8)[1:-1]\n",
    "    y_locs = np.linspace(0, image_shape[1], 8)[1:-1]\n",
    "\n",
    "    start_plane_mm = -vector_length_mm / 2\n",
    "    end_plane_mm = vector_length_mm / 2\n",
    "\n",
    "    # coloring array\n",
    "    T = np.linspace(0, 1, s) ** 2\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "    for x in x_locs:\n",
    "        for y in y_locs:\n",
    "            slope_matrix = generate_A_matrix(system.shift_order, [x], [y])\n",
    "            v1 = np.matmul(slope_matrix, coeffs0)[0]\n",
    "            v0 = np.matmul(slope_matrix, coeffs1)[0]\n",
    "\n",
    "            x_start = x + v0 * start_plane_mm\n",
    "            x_end = x + v0 * end_plane_mm\n",
    "            y_start = y + v1 * start_plane_mm\n",
    "            y_end = y + v1 * end_plane_mm\n",
    "\n",
    "            # segment length\n",
    "            s_x = (x_end - x_start) / s\n",
    "            s_y = (y_end - y_start) / s\n",
    "\n",
    "            colors = []\n",
    "            for i in range(0, s):\n",
    "                color = (1 - T[i], 0, T[i])\n",
    "                colors.append(color)\n",
    "                ax.plot(\n",
    "                    [x_start + s_x * i, x_start + (s_x * (i + 1))],\n",
    "                    [y_start + s_y * i, y_start + (s_y * (i + 1))],\n",
    "                    color=color,\n",
    "                )\n",
    "\n",
    "    plt.xlim([0, image_shape[0]])\n",
    "    plt.ylim([0, image_shape[1]])\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    if add_colorbar:\n",
    "        ax2 = fig.add_axes([0.95, 0.1, 0.03, 0.8])\n",
    "        cmap = matplotlib.colors.ListedColormap(np.flip(np.asarray(colors), axis=1))\n",
    "        norm = matplotlib.colors.Normalize(vmin=0, vmax=10)\n",
    "        matplotlib.colorbar.ColorbarBase(\n",
    "            ax2, cmap=cmap, norm=norm, spacing=\"proportional\", format=\"%1i\"\n",
    "        )\n",
    "\n",
    "    if add_title:\n",
    "        ax.set_title(f\"Axial Shifts for Camera {camera_number}\")\n",
    "        ax.set_xlabel(\"Pixel Location (X)\")\n",
    "        ax.set_ylabel(\"Pixel Location (Y)\")\n",
    "    return ax\n",
    "\n",
    "# showing all the vertices in each camera\n",
    "fig, axes = plt.subplots(6, 8)\n",
    "camera_numbers = np.arange(48)\n",
    "for camera_number in camera_numbers:\n",
    "    ax_num0 = 5 - (camera_number % 6)\n",
    "    ax_num1 = int(camera_number / 6)\n",
    "\n",
    "    axis = axes[ax_num0, ax_num1]\n",
    "    vector_plot(\n",
    "        camera_number=camera_number,\n",
    "        vector_length_mm=10,\n",
    "        ax=axis,\n",
    "        add_colorbar=False,\n",
    "        add_title=False,\n",
    "        s=3,\n",
    "    )\n",
    "\n",
    "    axis.set_xlim([0, image_shape[0]])\n",
    "    axis.set_ylim([0, image_shape[1]])\n",
    "\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])\n",
    "    axis.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filmscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
